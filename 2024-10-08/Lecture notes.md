
## Paper tips

- look at references
- Influential Michigan speech corpus
	- everyone cites a small part without context

- Pick a paper at least a week in advance
- Perceptual dialectology
	- betsy chapter


# Lotto & Holt

- Motor theory
	- relies on neural mechanisms specific to language

let's go back to history

1850s - 1860s

- Continental phonetics
	- tube with needle wiggles with audio waves, illustrate wave form
	- squeeze bulb measure pressure
- British phonetics
	- from philosophy / philology
	- influenced by indian languists
	- Panini
		- focus on making writing system for indian languages that didn't yet have one
		- often confused with sanskrit, but different
	- Underlying allophones
	- Surface forms phonemes
	- sequential idea of symbol into articulated sounds
	- language symbolic of the world
	- set of symbols we manipulate with thinking
	- platonic : "imperfect reflections"
	- panini : not imperfect, surface form

- early phoneticians thought miscalibrated instruments
- it was anticipatory articulation
	- we start to make gestures before sounds may occur
	- sometimes one articulator masks / overshadows another articulator

- motor systems
	- goal oriented
	- second thing (missed it)

- gestural blending
	- "hokey" k slides forward from stop in back and rolls forward
	- "ika"
	- two co-articulated sounds that make a new different sound
	- vowel deforms for uvular stop 
	- can slide K forward but not back
		- uvular stop to vowel
		- vowel is deformed

- american linguistics inherited british phonological system
	- not about how sounds made, but about contrasting sounds
	- uvular sound may not be made at uvula, but behind velar if lang has velar sounds
	- this doesn't work well for some linguistic contrasts
	- korean has three-way contrast for a langryeal sound
	- southern min has two-way contrast between (missed it)
	- contrasts useful for describing language
	- IPA is like this, and is an offshoot from an alphabet

- Stetson ~1900
	- no perception is about how sounds made
	- up still up til the 50s US lit still stuck with gesture and sounds and symbols being separate

- Spectrograms invented during WWII
	- Thought it could be useful for transferring information in an opaque way
	- had people read spectrograms in warehouses and transcribe
	- bad because
		- anyone can learn to read spectrogram
		- reading spectrograms are really hard
		- spectrograms of different things can look same
			- coarticulation makes sounds looks different
			- radio dialogue extra hard for all the coarticulation & sounds blending together
	- two diff ways to make a lateral in english
		- except not california
		- "please" and "fleece"
	- Ls are hard for a lot of speakers
		- rocking between left and right tongue shift can influence next sound because people were anticipatory gesturing for an L soon to occur

- electropalletography
	- 
	- found same problem as spectrograms & early calibration problem
	- saw anticipatory gesturing 
- obsterants
	- aperidoic sounds
	- release burst
- sonotorants
	- periodic
	- L and R (non-trilled)
(acousitic phonotecion version)

- cleft pallet hard to close velum and can't make velar stop
	- voiced nasals
- "smile"
	- unvoiced s sound and devoices M
	- can say smile without devoicing M but it sounds different and weird
- added info about proceeding and preceeding sounds
- segementalists don't like it
- welsh doesn't have L except in loan words

- vowel harmonization lip rounding keeps going
- phonetic co-articulatory thing that becomes encoded in language and the specific way you say a word


This inspired Motor Theory

- abstractness and invariance
- can also have a non-abstract and only auditory tho

- coarticulatory effects useful for recovering information 
- same for gestural information

- ( hot / hop / hock ) - release burst needed to distinguish (or context)

- motor theory has idea that we have gestures
- but also there's lots of other noise in background to filter
- but how do we separate gestures from those?
- proposed  general auditory theory


general auditory
- perception constrained by operating characteristics of the auditory system

motor theory
- came out of 50s with spectrograms and perceptual experiments
	- gesturally context dependent events

vowel space is not front / back of tract, it's relative to surrounding sounds 

![[Screenshot 2024-10-08 at 4.22.55 PM.png.webp]]

also proposing speech is special and unlike other sounds
- related to studying speech aquisition
	- but it's much more complex
- encourage us to take classes by (prof) or (other prof) 
- but it's way more complex than that


motor theory evidence

![[Screenshot 2024-10-08 at 4.24.18 PM.png.webp]]

pollock in the 50s saw you get 50 db signal boost to perceieved audio signal if you add visual 

haptic info- put your hand on someone's mouth in a noisy env and you get a lot extra info from feeling vibrations

- thought to be why speech is special, and thought why supposedly exlcusive to humans
- also thought that it gets harder to perceive things not in first lang later in life, also probs with this
	- thought that infants learning to speak language lost perception of non-relevant sounds
	- elided there must be a speech processor module in the brain

However problems:

![[Screenshot 2024-10-08 at 4.29.06 PM.png.webp]]

- oh but we use context too
- mcgurk not reliably equal across listeners but auditory perception is
	- mcgurk effect pushed around by probabilities of sequential words
	- was supposedly pre-cortex processing, but this refutes it, mcgurk effect tossed out
- duplex perception
	- non-speech tasks work too, we attune to non-speech sounds
	- not evidence for motor theory
- categorical percpetion
	- also not
	- japanese quail performs categorically in response to human speech and quail sounds
	- contrastive VOT in French
	- asking "is this sound in this set of words or this one"
	- cot / caught merger
- invariance is a problem
	- lots of variation
	- speech not observed as an abstraction
	- can recognize speaker by very small amount voicing
- refutes speech module

Modern motor theory

![[Screenshot 2024-10-08 at 4.39.06 PM.png.webp]]

- converges back to allophones / phonemes
- still listtle evidence for a phone-based or alphabetic representation in non-literate populations
- evidence of perceptional reorg in infants during motor-learning phases of lang acquisition 
	- 3-6 months infants specialize in perceiving audio even before anatomy developed to make that sound
- s is complex but very common, why is theta so uncommon relatively?
	- (missed it)

![[Screenshot 2024-10-08 at 4.44.53 PM.png.webp]]

General auditory
- not the auditorist version of motor theory that auditorists pushed back against
- auditory perception is integrated with the rest of our brain
	- includes afferent system of mechanical signals
	- includes cognition learning etc
	- but also brain sends signals to cochlea that stiffens/softens it to make it more/less sensitive to certain sounds
	- lateral compression to suppres background noise
- relies on auditory distinctiveness
	- dr wright: wished that they highlighted this more in paper, wished they cited more recent stuff
	- more distinct sounds easier to survive noisyness of communication
- word "knowledge"
	- K sound used to be there historically
	- still preserved in "Acknowledged"
- some sounds don't get maintained in a language if they're hard to hear
	- V and TH sound: V tends to win since it has more gestural information
- speakers adapt to accomodate listeners
	- lobard reflex
	- not actually reflex
	- people tend to talk louder in presence of noise
		- but not always and not always automatic
	- might be since you listen to yourself to so you could hear

![[Screenshot 2024-10-08 at 4.51.45 PM.png.webp]]
- Double weak (neary 1992) and Dual Stream (hickok & poeppel 200{0,4,7})
	- despite strong auditory approaches, there are times when motor areas of brain used for speech perception
		- perception draws on all the info it can
- motor theory says it has to be gestures and has to have gestures
- gesturalists said only audio no gesture
- double weak says it takes both
- 
![[Screenshot 2024-10-08 at 4.54.22 PM.png.webp]]

- "a little bit" in this clip sounds like "blbi"
- "dirty" extra articulated for pragmatic reasons
- she knows you'll recover the "a little bit" with context so it's not very emphasized


Hickok & poeppel: model of cortical network

![[Screenshot 2024-10-08 at 5.00.13 PM.png.webp]]

dual stream model

![[Screenshot 2024-10-08 at 5.00.49 PM.png.webp]]

laughing / crying can make it hard to make a sentence, needs continuous uninterrupted stream

motor area might be skipped or engaged

![[Screenshot 2024-10-08 at 5.02.45 PM.png.webp]]

articulators aren't flying around independently of our brains

things that comes out of mouth are planned ahead of time to come out that way

poinding on your chest isn't planned as part of the speech process, but the airflow toward the end is

gets modified over time based on feedback
- increase volume mid sentence people will start getting louder to compensate

size of breath varies with size of planned utterance (and compensate if needed)

proprier-receptive feedback
- if you numb someone's tongue, they have trouble talking, not vowels but consonants

california vowel space is shaped like california
- no rounded vowels w lip movement
- "dude" wisconsin / california 


model picture above doesn't factor in bias
- stereotypes based on context / visual 

gestural drift
- andrea mccloud 

testosterone found to impact word production

(small aside: thanks for mentioning the bit about testosterone and impact on speech! that’s really interesting and I’m gonna go read more; also I wonder if they studied across populations who did or didn’t do vocal training)
